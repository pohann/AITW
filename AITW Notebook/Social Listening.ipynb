{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./comment.csv')\n",
    "df = df.rename(columns = {'0':'COMMENTS'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file\n",
    "df.to_csv('./comment.csv',encoding = 'utf_8_sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.download_data_gdown(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of comments: %i\"%df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=[1,2]\n",
    "test2=[2,2,2]\n",
    "assert len(test1) == len(test2), 'Lists with different lengths'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating wordcloud of FB comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "ws = WS(\"./data\")\n",
    "pos = POS(\"./data\")\n",
    "ner = NER(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting all comments\n",
    "comment = []\n",
    "for i in range(10):\n",
    "    comment.append(str(df['COMMENTS'][i]))\n",
    "\n",
    "ws_comment = ws(comment)\n",
    "pos_comment = pos(ws_comment)\n",
    "entity_comment = ner(ws_comment,pos_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting all comments\n",
    "comment = []\n",
    "for i in range(len(df['COMMENTS'])):\n",
    "    comment.append(str(df['COMMENTS'][i]))\n",
    "\n",
    "ws_comment = ws(comment)\n",
    "pos_comment = pos(ws_comment)\n",
    "entity_comment = ner(ws_comment,pos_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists of ignoring words\n",
    "#ignore_words = []\n",
    "ignore_words\n",
    "print(ignore_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words that should be ignore\n",
    "ignore_index = []\n",
    "for i in range(len(pos_comment)):\n",
    "    for j in range(len(pos_comment[i])):\n",
    "        if pos_comment[i][j] == 'Nh':\n",
    "            ignore_index.append([i,j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_index = ignore_index[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ignore_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_comment[3440][35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comment = ws(['聽'])\n",
    "test_pos_comment = pos(test_comment)\n",
    "print(test_pos_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_duplicate = ws_comment\n",
    "ws_duplicate[3440][35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index in ignore_index:\n",
    "    if len(ws_duplicate[index[0]]) == 1:\n",
    "        continue\n",
    "    else:\n",
    "        del ws_duplicate[index[0]][index[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the segmented words into .txt\n",
    "with open('comment.txt', 'w') as c:\n",
    "    for sentence in ws_duplicate:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                c.write('%s,'%word)\n",
    "            except UnicodeEncodeError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "text = open('comment.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "font = \"C:\\Windows\\Fonts\\mingliu.ttc\"\n",
    "wc = WordCloud(font_path=font,width=1200,height=600,max_font_size=180)\n",
    "wc.generate(text)\n",
    "wc.to_file(\"./wordcloud.png\")\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional print out function\n",
    "def print_word_pos_sentence(word_sentence, pos_sentence):\n",
    "    #if two lists have different lenghts, raise assertion error\n",
    "    assert len(word_sentence) == len(pos_sentence)\n",
    "    for word, pos in zip(word_sentence, pos_sentence):\n",
    "        print(f\"{word}({pos})\", end=\"\\u3000\")\n",
    "    print()\n",
    "    return\n",
    "for i, sentence in enumerate(comment):\n",
    "    print()\n",
    "    print(f\"'{sentence}'\")\n",
    "    print_word_pos_sentence(ws_comment[i],  pos_comment[i])\n",
    "    for entity in sorted(entity_comment[i]):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "post_df = pd.read_csv('./post.csv')\n",
    "post_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r'C:\\Users\\User\\Anaconda3\\envs\\tflow\\Lib\\site-packages\\parso\\python')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://zh-tw.facebook.com/')\n",
    "#logging in\n",
    "username = driver.find_elements_by_css_selector(\"input[name=email]\")\n",
    "username[0].send_keys('ib101301002@gmail.com')\n",
    "password = driver.find_elements_by_css_selector(\"input[name=pass]\")\n",
    "password[0].send_keys('hsnu1257A')\n",
    "loginButton = driver.find_elements_by_xpath('//*[contains(@id,\"loginbutton\")]')\n",
    "loginButton[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many likes?\n",
    "like_list = []\n",
    "error_list = []\n",
    "so_far = 0\n",
    "from time import sleep\n",
    "for i in range(890,1000):\n",
    "    driver.get('https://www.facebook.com/'+post_df['POST_ID'][i])\n",
    "\n",
    "    try:\n",
    "        like_number = driver.find_elements_by_xpath('//*[@class=\"_3dlh _3dli\"]/span') #_3dlh _3dli\n",
    "        like_list.append(like_number[0].text)\n",
    "    except IndexError:\n",
    "        try:\n",
    "            like_number = driver.find_elements_by_xpath('//*[@class=\"_7gn0 _7gn1\"]/span') # _7gn0 _7gn1\n",
    "            like_list.append(like_number[0].text)\n",
    "        except IndexError:\n",
    "            like_list.append(None)\n",
    "            error_list.append(i)\n",
    "    so_far = i\n",
    "'''\n",
    "like_number = ''\n",
    "for w in like_str:\n",
    "    if w.isdigit():\n",
    "        like_number = like_number + w\n",
    "print(int(like_number))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df['NUM_LIKES'][890:1000] = like_list[0:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving file\n",
    "\n",
    "post_df.to_csv('./post.csv', encoding = 'utf_8_sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click 搜尋\n",
    "driver.find_elements_by_xpath('//*[@class=\"crm-submit-buttons\"]/span[1]/input[1]')[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click 搜尋\n",
    "pager = driver.find_elements_by_xpath('//*[@class=\"pam uiBoxLightblue uiMorePagerPrimary\"]')\n",
    "pager[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the link of like list\n",
    "\n",
    "like_link = []\n",
    "error_list = []\n",
    "so_far = 0\n",
    "from time import sleep\n",
    "for i in range(0,10):\n",
    "    driver.get('https://www.facebook.com/'+post_df['POST_ID'][i])\n",
    "\n",
    "    try:\n",
    "        likes = driver.find_elements_by_xpath('//*[@class=\"_3dlf\"]') #normal posts\n",
    "        like_link.append(likes[0].get_attribute(\"href\"))\n",
    "    except IndexError:\n",
    "        try:\n",
    "            likes = driver.find_elements_by_xpath('//*[@class=\"_7gm_\"]/span') #video\n",
    "            like_link.append(likes[0].get_attribute(\"href\"))\n",
    "        except IndexError:\n",
    "            like_link.append(None)\n",
    "            error_list.append(i)\n",
    "    so_far = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in likes page: clicking \"more\" until there is no \"more\"\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    sleep(0.5)\n",
    "    try:\n",
    "        more= driver.find_elements_by_xpath('//*[@class=\"pam uiBoxLightblue uiMorePagerPrimary\"]')\n",
    "        more[0].click()\n",
    "    except IndexError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all the proflie links\n",
    "user_list = []\n",
    "profiles = driver.find_elements_by_xpath('//*[contains(@class,\"_5j0e fsl fwb fcb\")]/a[1]')\n",
    "for profile in profiles:\n",
    "    user_list.append(profile.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete duplicate profile links\n",
    "\n",
    "import re\n",
    "\n",
    "user_set = set()\n",
    "for user in user_list:\n",
    "    text = user\n",
    "    m = re.search('(.+?)\\&', text)\n",
    "    user_set.add(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given the profile links, get the links to anything\n",
    "user_list = list(user_set)\n",
    "driver.get(user_list[1]+'&sk=likes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get liked pages for all the users\n",
    "\n",
    "scroll_time = 10\n",
    "pages_list = []\n",
    "user_list = list(user_set)\n",
    "for i in range(len(user_list)):\n",
    "    individual_pages = []\n",
    "    text = user_list[i]\n",
    "    like_page = text +'&sk=likes'\n",
    "    driver.get(like_page)\n",
    "    for i in range(scroll_time):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        sleep(1)\n",
    "        \n",
    "    pages = driver.find_elements_by_xpath('//*[contains(@class,\"fsl fwb fcb\")]')\n",
    "    for page in pages:\n",
    "        try:\n",
    "            individual_pages.append(page.text)\n",
    "        except AttributeError:\n",
    "            individual_pages.append(page[0].text)\n",
    "    pages_list.append(individual_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_dic = {}\n",
    "for pages in pages_list:\n",
    "    for page in pages:\n",
    "        if page in pages_dic.keys():\n",
    "            pages_dic[page] += 1\n",
    "        else:\n",
    "            pages_dic[page] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pages_dic.copy()\n",
    "sorted_x = sorted(x.items(), key=lambda kv: kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_x.reverse()\n",
    "sorted_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizing posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\"言論自由\":['言論','集社','自由'],\\\n",
    "          \"LGBTI\":['LGBT','LGBTI','同性','性別','兩性'],\\\n",
    "          \"生存權\":['難民','武裝','戰爭'],\\\n",
    "          \"環境土地\":['氣候','暖化'],\\\n",
    "          \"中國人權\":['中國','香港'],\\\n",
    "          \"廢除死刑\":['廢死','死刑']\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping ads posts info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "post_df = pd.read_csv('./0926AdsPosts.csv')\n",
    "post_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r'C:\\Users\\User\\Anaconda3\\envs\\tflow\\Lib\\site-packages\\parso\\python')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open a new web browser\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://zh-tw.facebook.com/')\n",
    "#logging in\n",
    "username = driver.find_elements_by_css_selector(\"input[name=email]\")\n",
    "username[0].send_keys('ib101301002@gmail.com')\n",
    "password = driver.find_elements_by_css_selector(\"input[name=pass]\")\n",
    "password[0].send_keys('hsnu1257A')\n",
    "loginButton = driver.find_elements_by_xpath('//*[contains(@name,\"login\")]')\n",
    "loginButton[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to Facebook business manager\n",
    "driver.get('https://business.facebook.com/adsmanager/pages?act=193515561207372&business_id=193512787874316')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touched_number = driver.find_elements_by_xpath('//*[@class=\"_qea\"]')\n",
    "touched_number[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see if an ad post has touched our customers\n",
    "from time import sleep\n",
    "\n",
    "for i in range(1275,len(post_df['ADS_ID'])):\n",
    "    search = driver.find_elements_by_xpath('//*[@placeholder=\"Search...\"]')\n",
    "    search[0].send_keys(str(post_df['ADS_ID'][i]))\n",
    "    sleep(0.5)\n",
    "    search_button = driver.find_elements_by_xpath('//*[@class=\" _t7v\"]')\n",
    "    search_button[0].click()\n",
    "    sleep(3)\n",
    "    touched_number = driver.find_elements_by_xpath('//*[@class=\"_qea\"]')\n",
    "    try:\n",
    "        int(touched_number[0].text)\n",
    "        post_df['PUBLISHED'][i] = 0\n",
    "    except:\n",
    "        post_df['PUBLISHED'][i] = 1\n",
    "    #clear search\n",
    "    sleep(1)\n",
    "    clear_button = driver.find_elements_by_xpath('//*[@class=\"img sp_TiTCV7RWws__1_5x sx_52b51e\"]')\n",
    "    clear_button[0].click()\n",
    "    sleep(1)\n",
    "    try:\n",
    "        clear_button = driver.find_elements_by_xpath('//*[@class=\"img sp_TiTCV7RWws__1_5x sx_52b51e\"]')\n",
    "        clear_button[0].click()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df.to_csv('./0926AdsPosts.csv',encoding = 'big5', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See who shared our posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "post_df = pd.read_csv('./0926AdsPosts.csv')\n",
    "post_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://zh-tw.facebook.com/')\n",
    "#logging in\n",
    "username = driver.find_elements_by_css_selector(\"input[name=email]\")\n",
    "username[0].send_keys('ib101301002@gmail.com')\n",
    "password = driver.find_elements_by_css_selector(\"input[name=pass]\")\n",
    "password[0].send_keys('hsnu1257A')\n",
    "loginButton = driver.find_elements_by_xpath('//*[contains(@name,\"login\")]')\n",
    "loginButton[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share = driver.find_elements_by_xpath('//*[@class=\"_355t _6iik\"]')\n",
    "share[0].click()\n",
    "sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1470",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-c8f267a4d7ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mshared_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m959\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mpost_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PUBLISHED'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.facebook.com/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ADS_ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4373\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 4375\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   4376\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1470"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import re\n",
    "\n",
    "shared_dict = {}\n",
    "for i in range(959,1500):\n",
    "    if post_df['PUBLISHED'][i] == 1:\n",
    "        driver.get('https://www.facebook.com/'+str(post_df['ADS_ID'][i]))\n",
    "        sleep(3)\n",
    "        shared_dict[str(post_df['ADS_ID'][i])] = []\n",
    "        #open the list of shares\n",
    "        try:\n",
    "            share = driver.find_elements_by_xpath('//*[@class=\"_355t _4vn2\"]')\n",
    "            share[0].click()\n",
    "            sleep(2)\n",
    "        except:\n",
    "            try:\n",
    "                share = driver.find_elements_by_xpath('//*[@class=\"_355t _6iik\"]')\n",
    "                share[0].click()\n",
    "                sleep(2)\n",
    "            except:\n",
    "                continue\n",
    "        #share[0].click()\n",
    "        j = 0\n",
    "        while j < 100000:\n",
    "            height = j*250\n",
    "            driver.execute_script(\"window.scrollTo(0, %s);\"%height)\n",
    "            #last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            sleep(1)\n",
    "            try:\n",
    "                #get profile links\n",
    "                profile_link = driver.find_elements_by_xpath('//*[@class=\"profileLink\"]')\n",
    "                text = str(profile_link[j].get_attribute(\"href\"))\n",
    "                shared_dict[str(post_df['ADS_ID'][i])].append(text)\n",
    "                j+=1\n",
    "            except IndexError:\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_dict['2679389648843301']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write files\n",
    "\n",
    "import csv\n",
    "csv_file = \"ads_shared.csv\"\n",
    "#use 'w' if you want to start writing a new file\n",
    "#use 'a' if you want to append data to existing file\n",
    "with open('ads_shared.csv', 'a') as f: \n",
    "    for key in shared_dict.keys():\n",
    "        for content in shared_dict[key]:\n",
    "            f.write(\"%s,%s\\n\"%(key,content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_profile_link(url):    \n",
    "    text = str(url)\n",
    "    m = re.search('(.+?)\\&', url)\n",
    "    if m == None:\n",
    "        return text\n",
    "    return m\n",
    "\n",
    "def access_like_page(profile_link):\n",
    "    return str(profile_link)+'&sk=likes'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
